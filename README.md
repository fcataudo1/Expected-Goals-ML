# Predizione Goal da un tiro (Expected Goals â€“ xG)

Questo progetto ha lâ€™obiettivo di realizzare una **soluzione di Machine Learning** per la predizione dellâ€™esito di un tiro nel calcio, utilizzando il dataset **StatsBomb Open Data**.  
Il problema Ã¨ formulato come un task di **classificazione binaria supervisionata**, in cui si prevede se un evento di tiro si concluderÃ  con un **Goal** oppure **No Goal**.

Il progetto Ã¨ stato sviluppato applicando esclusivamente le tecniche e gli approcci di Machine Learning studiati durante il corso, seguendo unâ€™intera pipeline end-to-end.

---

## ğŸ“Œ Scenario e Task
- **UnitÃ  di analisi**: evento di tiro (*shot*)
- **Target**:
  - `1` â†’ Goal
  - `0` â†’ No Goal
- **Tipo di problema**: classificazione binaria
- **Principali difficoltÃ **:
  - forte sbilanciamento delle classi
  - presenza di valori mancanti
  - struttura annidata dei dati
  - relazioni non lineari tra le feature

---

## ğŸ“Š Dataset
Il dataset utilizzato Ã¨ **StatsBomb Open Data**, che fornisce eventi calcistici in formato JSON.  
Per il progetto vengono considerati esclusivamente gli eventi di tipo **Shot**, estratti dai file `events/{match_id}.json`.

---

## âš™ï¸ Pipeline di Machine Learning
La pipeline implementata comprende i seguenti step:

1. **Caricamento e parsing dei dati**
2. **Pulizia e gestione dei valori mancanti**
3. **Feature engineering**:
   - distanza dalla porta
   - angolo di tiro
4. **Encoding delle feature categoriche**
5. **Suddivisione train/test stratificata**
6. **Addestramento dei modelli**
7. **Valutazione delle prestazioni**
8. **Analisi degli errori**

---

## ğŸ¤– Modelli utilizzati
Sono stati addestrati e confrontati i seguenti modelli, studiati durante il corso:

- **Naive Bayes** (baseline)
- **Decision Tree**
- **Random Forest**

La **Random Forest** risulta il modello con le migliori prestazioni complessive.

---

## ğŸ“ˆ Metriche di valutazione
Considerata la natura sbilanciata del problema, sono state utilizzate metriche tradizionali ma informative:

- Accuracy (con discussione critica)
- Precision
- Recall
- F1-score
- ROC-AUC
- Confusion Matrix
- Precisionâ€“Recall Curve

---

## ğŸ“‚ Struttura del progetto
ProgettoML/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ load_data.py
â”‚ â”œâ”€â”€ feature_engineering.py
â”‚ â”œâ”€â”€ train_models.py
â”‚ â””â”€â”€ evaluate.py
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ events/ # file events StatsBomb
â”‚
â”œâ”€â”€ plots/ # grafici generati
â”œâ”€â”€ report.pdf
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## â–¶ï¸ Esecuzione
1. Posizionare i file `events/*.json` del dataset StatsBomb nella cartella:

data/events/
2. Installare le dipendenze:
```bash
pip install -r requirements.txt
```

3.Eseguire il progetto:
python main.py

Lâ€™esecuzione produrrÃ :
- metriche di valutazione a terminale
- grafici (ROC, Precisionâ€“Recall, Confusion Matrix) nella cartella plots/